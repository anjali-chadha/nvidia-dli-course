{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g-atf3gekcgR"
   },
   "source": [
    "# Assessment 1: I can train and deploy a neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_7wkT17FkmU6"
   },
   "source": [
    "At this point, you've worked through a full deep learning workflow. You've loaded a dataset, trained a model, and deployed your model into a simple application. Validate your learning by attempting to replicate that workflow with a new problem.\n",
    "\n",
    "We've included a dataset which consists of two classes:  \n",
    "\n",
    "1) Face: Contains images which include the face of a whale  \n",
    "2) Not Face: Contains images which do not include the face of a whale.  \n",
    "\n",
    "The dataset is located at ```/dli/data/whale/data/train```.\n",
    "\n",
    "Your challenge is:\n",
    "\n",
    "1) Use [DIGITS](/digits) to train a model to identify *new* whale faces with an accuracy of more than 80%.   \n",
    "\n",
    "2) Deploy your model by modifying and saving the python application [submission.py](../../../../edit/tasks/task-assessment/task/submission.py) to return the word \"whale\" if the image contains a whale's face and \"not whale\" if the image does not.  \n",
    "\n",
    "Resources:\n",
    "\n",
    "1) [Train a model](../../task1/task/Train%20a%20Model.ipynb)  \n",
    "2) [New Data as a goal](../../task2/task/New%20Data%20as%20a%20Goal.ipynb)  \n",
    "3) [Deployment](../../task3/task/Deployment.ipynb)  \n",
    "\n",
    "Suggestions: \n",
    "\n",
    "- Use empty code blocks to find out any informantion necessary to solve this problem: eg: ```!ls [directorypath] prints the files in a given directory``` \n",
    "- Executing the first two cells below will run your python script with test images, the first should return \"whale\" and the second should return \"not whale\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YaaY1Vb3o3mC"
   },
   "source": [
    "Start in [DIGITS](/digits/). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create_train_db.log  labels.txt        mean.jpg       train.txt  val.txt\r\n",
      "create_val_db.log    mean.binaryproto  status.pickle  train_db\t val_db\r\n"
     ]
    }
   ],
   "source": [
    "! ls /dli/data/digits/20190201-221714-3580"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0201 22:41:34.643050   218 gpu_memory.cpp:105] GPUMemory::Manager initialized\n",
      "I0201 22:41:34.643777   218 gpu_memory.cpp:107] Total memory: 11996954624, Free: 11790385152, dev_info[0]: total=11996954624 free=11790385152\n",
      "W0201 22:41:34.643851   218 _caffe.cpp:172] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0201 22:41:34.643983   218 _caffe.cpp:173] Use this instead (with the named \"weights\" parameter):\n",
      "W0201 22:41:34.644001   218 _caffe.cpp:175] Net('/dli/data/digits/20190201-222749-1fd6/deploy.prototxt', 1, weights='/dli/data/digits/20190201-222749-1fd6/snapshot_iter_540.caffemodel')\n",
      "I0201 22:41:34.644347   218 upgrade_proto.cpp:66] Attempting to upgrade input file specified using deprecated input fields: /dli/data/digits/20190201-222749-1fd6/deploy.prototxt\n",
      "I0201 22:41:34.644377   218 upgrade_proto.cpp:69] Successfully upgraded file specified using deprecated input fields.\n",
      "W0201 22:41:34.644389   218 upgrade_proto.cpp:71] Note that future Caffe releases will only support input layers and not input fields.\n",
      "I0201 22:41:34.654551   218 net.cpp:79] Initializing net from parameters: \n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"input\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 1\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"conv2\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0.1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"conv3\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0.1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0.1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.005\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0.1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.005\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0.1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc8\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc8\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  inner_product_param {\n",
      "    num_output: 2\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"softmax\"\n",
      "  type: \"Softmax\"\n",
      "  bottom: \"fc8\"\n",
      "  top: \"softmax\"\n",
      "}\n",
      "I0201 22:41:34.654963   218 net.cpp:109] Using FLOAT as default forward math type\n",
      "I0201 22:41:34.654979   218 net.cpp:115] Using FLOAT as default backward math type\n",
      "I0201 22:41:34.654989   218 layer_factory.hpp:172] Creating layer 'input' of type 'Input'\n",
      "I0201 22:41:34.655002   218 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0201 22:41:34.655021   218 net.cpp:199] Created Layer input (0)\n",
      "I0201 22:41:34.655032   218 net.cpp:541] input -> data\n",
      "I0201 22:41:34.655766   218 net.cpp:259] Setting up input\n",
      "I0201 22:41:34.655792   218 net.cpp:266] TEST Top shape for layer 0 'input' 1 3 227 227 (154587)\n",
      "I0201 22:41:34.655809   218 layer_factory.hpp:172] Creating layer 'conv1' of type 'Convolution'\n",
      "I0201 22:41:34.655822   218 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0201 22:41:34.655861   218 net.cpp:199] Created Layer conv1 (1)\n",
      "I0201 22:41:34.655876   218 net.cpp:571] conv1 <- data\n",
      "I0201 22:41:34.655890   218 net.cpp:541] conv1 -> conv1\n",
      "I0201 22:41:35.215821   218 net.cpp:259] Setting up conv1\n",
      "I0201 22:41:35.215878   218 net.cpp:266] TEST Top shape for layer 1 'conv1' 1 96 55 55 (290400)\n",
      "I0201 22:41:35.215911   218 layer_factory.hpp:172] Creating layer 'relu1' of type 'ReLU'\n",
      "I0201 22:41:35.215929   218 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0201 22:41:35.215947   218 net.cpp:199] Created Layer relu1 (2)\n",
      "I0201 22:41:35.215960   218 net.cpp:571] relu1 <- conv1\n",
      "I0201 22:41:35.215970   218 net.cpp:526] relu1 -> conv1 (in-place)\n",
      "I0201 22:41:35.216001   218 net.cpp:259] Setting up relu1\n",
      "I0201 22:41:35.216014   218 net.cpp:266] TEST Top shape for layer 2 'relu1' 1 96 55 55 (290400)\n",
      "I0201 22:41:35.216028   218 layer_factory.hpp:172] Creating layer 'norm1' of type 'LRN'\n",
      "I0201 22:41:35.216040   218 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0201 22:41:35.216065   218 net.cpp:199] Created Layer norm1 (3)\n",
      "I0201 22:41:35.216076   218 net.cpp:571] norm1 <- conv1\n",
      "I0201 22:41:35.216084   218 net.cpp:541] norm1 -> norm1\n",
      "I0201 22:41:35.216151   218 net.cpp:259] Setting up norm1\n",
      "I0201 22:41:35.216169   218 net.cpp:266] TEST Top shape for layer 3 'norm1' 1 96 55 55 (290400)\n",
      "I0201 22:41:35.216177   218 layer_factory.hpp:172] Creating layer 'pool1' of type 'Pooling'\n",
      "I0201 22:41:35.216186   218 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0201 22:41:35.216234   218 net.cpp:199] Created Layer pool1 (4)\n",
      "I0201 22:41:35.216248   218 net.cpp:571] pool1 <- norm1\n",
      "I0201 22:41:35.216254   218 net.cpp:541] pool1 -> pool1\n",
      "I0201 22:41:35.216320   218 net.cpp:259] Setting up pool1\n",
      "I0201 22:41:35.216337   218 net.cpp:266] TEST Top shape for layer 4 'pool1' 1 96 27 27 (69984)\n",
      "I0201 22:41:35.216347   218 layer_factory.hpp:172] Creating layer 'conv2' of type 'Convolution'\n",
      "I0201 22:41:35.216358   218 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0201 22:41:35.216379   218 net.cpp:199] Created Layer conv2 (5)\n",
      "I0201 22:41:35.216390   218 net.cpp:571] conv2 <- pool1\n",
      "I0201 22:41:35.216398   218 net.cpp:541] conv2 -> conv2\n",
      "I0201 22:41:35.223589   218 net.cpp:259] Setting up conv2\n",
      "I0201 22:41:35.223618   218 net.cpp:266] TEST Top shape for layer 5 'conv2' 1 256 27 27 (186624)\n",
      "I0201 22:41:35.223637   218 layer_factory.hpp:172] Creating layer 'relu2' of type 'ReLU'\n",
      "I0201 22:41:35.223650   218 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0201 22:41:35.223659   218 net.cpp:199] Created Layer relu2 (6)\n",
      "I0201 22:41:35.223671   218 net.cpp:571] relu2 <- conv2\n",
      "I0201 22:41:35.223683   218 net.cpp:526] relu2 -> conv2 (in-place)\n",
      "I0201 22:41:35.223700   218 net.cpp:259] Setting up relu2\n",
      "I0201 22:41:35.223711   218 net.cpp:266] TEST Top shape for layer 6 'relu2' 1 256 27 27 (186624)\n",
      "I0201 22:41:35.223723   218 layer_factory.hpp:172] Creating layer 'norm2' of type 'LRN'\n",
      "I0201 22:41:35.223734   218 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0201 22:41:35.223752   218 net.cpp:199] Created Layer norm2 (7)\n",
      "I0201 22:41:35.223762   218 net.cpp:571] norm2 <- conv2\n",
      "I0201 22:41:35.223775   218 net.cpp:541] norm2 -> norm2\n",
      "I0201 22:41:35.223829   218 net.cpp:259] Setting up norm2\n",
      "I0201 22:41:35.223845   218 net.cpp:266] TEST Top shape for layer 7 'norm2' 1 256 27 27 (186624)\n",
      "I0201 22:41:35.223857   218 layer_factory.hpp:172] Creating layer 'pool2' of type 'Pooling'\n",
      "I0201 22:41:35.223868   218 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0201 22:41:35.223883   218 net.cpp:199] Created Layer pool2 (8)\n",
      "I0201 22:41:35.223896   218 net.cpp:571] pool2 <- norm2\n",
      "I0201 22:41:35.223902   218 net.cpp:541] pool2 -> pool2\n",
      "I0201 22:41:35.223959   218 net.cpp:259] Setting up pool2\n",
      "I0201 22:41:35.223975   218 net.cpp:266] TEST Top shape for layer 8 'pool2' 1 256 13 13 (43264)\n",
      "I0201 22:41:35.223989   218 layer_factory.hpp:172] Creating layer 'conv3' of type 'Convolution'\n",
      "I0201 22:41:35.224001   218 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0201 22:41:35.224021   218 net.cpp:199] Created Layer conv3 (9)\n",
      "I0201 22:41:35.224032   218 net.cpp:571] conv3 <- pool2\n",
      "I0201 22:41:35.224045   218 net.cpp:541] conv3 -> conv3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0201 22:41:35.240083   218 net.cpp:259] Setting up conv3\n",
      "I0201 22:41:35.240111   218 net.cpp:266] TEST Top shape for layer 9 'conv3' 1 384 13 13 (64896)\n",
      "I0201 22:41:35.240125   218 layer_factory.hpp:172] Creating layer 'relu3' of type 'ReLU'\n",
      "I0201 22:41:35.240140   218 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0201 22:41:35.240149   218 net.cpp:199] Created Layer relu3 (10)\n",
      "I0201 22:41:35.240157   218 net.cpp:571] relu3 <- conv3\n",
      "I0201 22:41:35.240165   218 net.cpp:526] relu3 -> conv3 (in-place)\n",
      "I0201 22:41:35.240177   218 net.cpp:259] Setting up relu3\n",
      "I0201 22:41:35.240190   218 net.cpp:266] TEST Top shape for layer 10 'relu3' 1 384 13 13 (64896)\n",
      "I0201 22:41:35.240196   218 layer_factory.hpp:172] Creating layer 'conv4' of type 'Convolution'\n",
      "I0201 22:41:35.240207   218 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0201 22:41:35.240222   218 net.cpp:199] Created Layer conv4 (11)\n",
      "I0201 22:41:35.240232   218 net.cpp:571] conv4 <- conv3\n",
      "I0201 22:41:35.240239   218 net.cpp:541] conv4 -> conv4\n",
      "I0201 22:41:35.252692   218 net.cpp:259] Setting up conv4\n",
      "I0201 22:41:35.252719   218 net.cpp:266] TEST Top shape for layer 11 'conv4' 1 384 13 13 (64896)\n",
      "I0201 22:41:35.252758   218 layer_factory.hpp:172] Creating layer 'relu4' of type 'ReLU'\n",
      "I0201 22:41:35.252768   218 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0201 22:41:35.252777   218 net.cpp:199] Created Layer relu4 (12)\n",
      "I0201 22:41:35.252790   218 net.cpp:571] relu4 <- conv4\n",
      "I0201 22:41:35.252797   218 net.cpp:526] relu4 -> conv4 (in-place)\n",
      "I0201 22:41:35.252812   218 net.cpp:259] Setting up relu4\n",
      "I0201 22:41:35.252821   218 net.cpp:266] TEST Top shape for layer 12 'relu4' 1 384 13 13 (64896)\n",
      "I0201 22:41:35.252835   218 layer_factory.hpp:172] Creating layer 'conv5' of type 'Convolution'\n",
      "I0201 22:41:35.252840   218 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0201 22:41:35.252859   218 net.cpp:199] Created Layer conv5 (13)\n",
      "I0201 22:41:35.252871   218 net.cpp:571] conv5 <- conv4\n",
      "I0201 22:41:35.252883   218 net.cpp:541] conv5 -> conv5\n",
      "I0201 22:41:35.261049   218 net.cpp:259] Setting up conv5\n",
      "I0201 22:41:35.261073   218 net.cpp:266] TEST Top shape for layer 13 'conv5' 1 256 13 13 (43264)\n",
      "I0201 22:41:35.261090   218 layer_factory.hpp:172] Creating layer 'relu5' of type 'ReLU'\n",
      "I0201 22:41:35.261104   218 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0201 22:41:35.261113   218 net.cpp:199] Created Layer relu5 (14)\n",
      "I0201 22:41:35.261126   218 net.cpp:571] relu5 <- conv5\n",
      "I0201 22:41:35.261132   218 net.cpp:526] relu5 -> conv5 (in-place)\n",
      "I0201 22:41:35.261147   218 net.cpp:259] Setting up relu5\n",
      "I0201 22:41:35.261159   218 net.cpp:266] TEST Top shape for layer 14 'relu5' 1 256 13 13 (43264)\n",
      "I0201 22:41:35.261171   218 layer_factory.hpp:172] Creating layer 'pool5' of type 'Pooling'\n",
      "I0201 22:41:35.261183   218 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0201 22:41:35.261198   218 net.cpp:199] Created Layer pool5 (15)\n",
      "I0201 22:41:35.261209   218 net.cpp:571] pool5 <- conv5\n",
      "I0201 22:41:35.261222   218 net.cpp:541] pool5 -> pool5\n",
      "I0201 22:41:35.261284   218 net.cpp:259] Setting up pool5\n",
      "I0201 22:41:35.261301   218 net.cpp:266] TEST Top shape for layer 15 'pool5' 1 256 6 6 (9216)\n",
      "I0201 22:41:35.261312   218 layer_factory.hpp:172] Creating layer 'fc6' of type 'InnerProduct'\n",
      "I0201 22:41:35.261325   218 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0201 22:41:35.261337   218 net.cpp:199] Created Layer fc6 (16)\n",
      "I0201 22:41:35.261349   218 net.cpp:571] fc6 <- pool5\n",
      "I0201 22:41:35.261355   218 net.cpp:541] fc6 -> fc6\n",
      "I0201 22:41:35.963294   218 net.cpp:259] Setting up fc6\n",
      "I0201 22:41:35.963351   218 net.cpp:266] TEST Top shape for layer 16 'fc6' 1 4096 (4096)\n",
      "I0201 22:41:35.963373   218 layer_factory.hpp:172] Creating layer 'relu6' of type 'ReLU'\n",
      "I0201 22:41:35.963390   218 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0201 22:41:35.963405   218 net.cpp:199] Created Layer relu6 (17)\n",
      "I0201 22:41:35.963418   218 net.cpp:571] relu6 <- fc6\n",
      "I0201 22:41:35.963431   218 net.cpp:526] relu6 -> fc6 (in-place)\n",
      "I0201 22:41:35.963454   218 net.cpp:259] Setting up relu6\n",
      "I0201 22:41:35.963465   218 net.cpp:266] TEST Top shape for layer 17 'relu6' 1 4096 (4096)\n",
      "I0201 22:41:35.963472   218 layer_factory.hpp:172] Creating layer 'drop6' of type 'Dropout'\n",
      "I0201 22:41:35.963485   218 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0201 22:41:35.963500   218 net.cpp:199] Created Layer drop6 (18)\n",
      "I0201 22:41:35.963510   218 net.cpp:571] drop6 <- fc6\n",
      "I0201 22:41:35.963516   218 net.cpp:526] drop6 -> fc6 (in-place)\n",
      "I0201 22:41:35.998006   218 net.cpp:259] Setting up drop6\n",
      "I0201 22:41:35.998033   218 net.cpp:266] TEST Top shape for layer 18 'drop6' 1 4096 (4096)\n",
      "I0201 22:41:35.998047   218 layer_factory.hpp:172] Creating layer 'fc7' of type 'InnerProduct'\n",
      "I0201 22:41:35.998064   218 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0201 22:41:35.998078   218 net.cpp:199] Created Layer fc7 (19)\n",
      "I0201 22:41:35.998121   218 net.cpp:571] fc7 <- fc6\n",
      "I0201 22:41:35.998129   218 net.cpp:541] fc7 -> fc7\n",
      "I0201 22:41:36.310608   218 net.cpp:259] Setting up fc7\n",
      "I0201 22:41:36.310665   218 net.cpp:266] TEST Top shape for layer 19 'fc7' 1 4096 (4096)\n",
      "I0201 22:41:36.310688   218 layer_factory.hpp:172] Creating layer 'relu7' of type 'ReLU'\n",
      "I0201 22:41:36.310704   218 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0201 22:41:36.310721   218 net.cpp:199] Created Layer relu7 (20)\n",
      "I0201 22:41:36.310736   218 net.cpp:571] relu7 <- fc7\n",
      "I0201 22:41:36.310753   218 net.cpp:526] relu7 -> fc7 (in-place)\n",
      "I0201 22:41:36.310778   218 net.cpp:259] Setting up relu7\n",
      "I0201 22:41:36.310791   218 net.cpp:266] TEST Top shape for layer 20 'relu7' 1 4096 (4096)\n",
      "I0201 22:41:36.310803   218 layer_factory.hpp:172] Creating layer 'drop7' of type 'Dropout'\n",
      "I0201 22:41:36.310815   218 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0201 22:41:36.310835   218 net.cpp:199] Created Layer drop7 (21)\n",
      "I0201 22:41:36.310847   218 net.cpp:571] drop7 <- fc7\n",
      "I0201 22:41:36.310858   218 net.cpp:526] drop7 -> fc7 (in-place)\n",
      "I0201 22:41:36.345434   218 net.cpp:259] Setting up drop7\n",
      "I0201 22:41:36.345459   218 net.cpp:266] TEST Top shape for layer 21 'drop7' 1 4096 (4096)\n",
      "I0201 22:41:36.345468   218 layer_factory.hpp:172] Creating layer 'fc8' of type 'InnerProduct'\n",
      "I0201 22:41:36.345479   218 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0201 22:41:36.345494   218 net.cpp:199] Created Layer fc8 (22)\n",
      "I0201 22:41:36.345507   218 net.cpp:571] fc8 <- fc7\n",
      "I0201 22:41:36.345515   218 net.cpp:541] fc8 -> fc8\n",
      "I0201 22:41:36.346546   218 net.cpp:259] Setting up fc8\n",
      "I0201 22:41:36.346571   218 net.cpp:266] TEST Top shape for layer 22 'fc8' 1 2 (2)\n",
      "I0201 22:41:36.346590   218 layer_factory.hpp:172] Creating layer 'softmax' of type 'Softmax'\n",
      "I0201 22:41:36.346606   218 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0201 22:41:36.346622   218 net.cpp:199] Created Layer softmax (23)\n",
      "I0201 22:41:36.346634   218 net.cpp:571] softmax <- fc8\n",
      "I0201 22:41:36.346642   218 net.cpp:541] softmax -> softmax\n",
      "I0201 22:41:36.346726   218 net.cpp:259] Setting up softmax\n",
      "I0201 22:41:36.346746   218 net.cpp:266] TEST Top shape for layer 23 'softmax' 1 2 (2)\n",
      "I0201 22:41:36.346758   218 net.cpp:337] softmax does not need backward computation.\n",
      "I0201 22:41:36.346765   218 net.cpp:337] fc8 does not need backward computation.\n",
      "I0201 22:41:36.346776   218 net.cpp:337] drop7 does not need backward computation.\n",
      "I0201 22:41:36.346782   218 net.cpp:337] relu7 does not need backward computation.\n",
      "I0201 22:41:36.346792   218 net.cpp:337] fc7 does not need backward computation.\n",
      "I0201 22:41:36.346798   218 net.cpp:337] drop6 does not need backward computation.\n",
      "I0201 22:41:36.346809   218 net.cpp:337] relu6 does not need backward computation.\n",
      "I0201 22:41:36.346817   218 net.cpp:337] fc6 does not need backward computation.\n",
      "I0201 22:41:36.346824   218 net.cpp:337] pool5 does not need backward computation.\n",
      "I0201 22:41:36.346832   218 net.cpp:337] relu5 does not need backward computation.\n",
      "I0201 22:41:36.346839   218 net.cpp:337] conv5 does not need backward computation.\n",
      "I0201 22:41:36.346848   218 net.cpp:337] relu4 does not need backward computation.\n",
      "I0201 22:41:36.346859   218 net.cpp:337] conv4 does not need backward computation.\n",
      "I0201 22:41:36.346865   218 net.cpp:337] relu3 does not need backward computation.\n",
      "I0201 22:41:36.346871   218 net.cpp:337] conv3 does not need backward computation.\n",
      "I0201 22:41:36.346880   218 net.cpp:337] pool2 does not need backward computation.\n",
      "I0201 22:41:36.346889   218 net.cpp:337] norm2 does not need backward computation.\n",
      "I0201 22:41:36.346894   218 net.cpp:337] relu2 does not need backward computation.\n",
      "I0201 22:41:36.346904   218 net.cpp:337] conv2 does not need backward computation.\n",
      "I0201 22:41:36.346912   218 net.cpp:337] pool1 does not need backward computation.\n",
      "I0201 22:41:36.346951   218 net.cpp:337] norm1 does not need backward computation.\n",
      "I0201 22:41:36.346962   218 net.cpp:337] relu1 does not need backward computation.\n",
      "I0201 22:41:36.346973   218 net.cpp:337] conv1 does not need backward computation.\n",
      "I0201 22:41:36.346985   218 net.cpp:337] input does not need backward computation.\n",
      "I0201 22:41:36.346995   218 net.cpp:379] This network produces output softmax\n",
      "I0201 22:41:36.347026   218 net.cpp:402] Top memory (TEST) required for data: 8315264 diff: 8315264\n",
      "I0201 22:41:36.347038   218 net.cpp:405] Bottom memory (TEST) required for data: 8315256 diff: 8315256\n",
      "I0201 22:41:36.347050   218 net.cpp:408] Shared (in-place) memory (TEST) by data: 2665856 diff: 2665856\n",
      "I0201 22:41:36.347056   218 net.cpp:411] Parameters memory (TEST) required for data: 227505672 diff: 227505672\n",
      "I0201 22:41:36.347065   218 net.cpp:414] Parameters shared memory (TEST) by data: 0 diff: 0\n",
      "I0201 22:41:36.347071   218 net.cpp:420] Network initialization done.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0201 22:41:36.484081   218 net.cpp:1129] Ignoring source layer train-data\n",
      "I0201 22:41:36.484124   218 net.cpp:1137] Copying source layer conv1 Type:Convolution #blobs=2\n",
      "I0201 22:41:36.484236   218 net.cpp:1137] Copying source layer relu1 Type:ReLU #blobs=0\n",
      "I0201 22:41:36.484251   218 net.cpp:1137] Copying source layer norm1 Type:LRN #blobs=0\n",
      "I0201 22:41:36.484258   218 net.cpp:1137] Copying source layer pool1 Type:Pooling #blobs=0\n",
      "I0201 22:41:36.484270   218 net.cpp:1137] Copying source layer conv2 Type:Convolution #blobs=2\n",
      "I0201 22:41:36.484505   218 net.cpp:1137] Copying source layer relu2 Type:ReLU #blobs=0\n",
      "I0201 22:41:36.484519   218 net.cpp:1137] Copying source layer norm2 Type:LRN #blobs=0\n",
      "I0201 22:41:36.484525   218 net.cpp:1137] Copying source layer pool2 Type:Pooling #blobs=0\n",
      "I0201 22:41:36.484530   218 net.cpp:1137] Copying source layer conv3 Type:Convolution #blobs=2\n",
      "I0201 22:41:36.485163   218 net.cpp:1137] Copying source layer relu3 Type:ReLU #blobs=0\n",
      "I0201 22:41:36.485179   218 net.cpp:1137] Copying source layer conv4 Type:Convolution #blobs=2\n",
      "I0201 22:41:36.485611   218 net.cpp:1137] Copying source layer relu4 Type:ReLU #blobs=0\n",
      "I0201 22:41:36.485625   218 net.cpp:1137] Copying source layer conv5 Type:Convolution #blobs=2\n",
      "I0201 22:41:36.485918   218 net.cpp:1137] Copying source layer relu5 Type:ReLU #blobs=0\n",
      "I0201 22:41:36.485934   218 net.cpp:1137] Copying source layer pool5 Type:Pooling #blobs=0\n",
      "I0201 22:41:36.485939   218 net.cpp:1137] Copying source layer fc6 Type:InnerProduct #blobs=2\n",
      "I0201 22:41:36.508821   218 net.cpp:1137] Copying source layer relu6 Type:ReLU #blobs=0\n",
      "I0201 22:41:36.508857   218 net.cpp:1137] Copying source layer drop6 Type:Dropout #blobs=0\n",
      "I0201 22:41:36.508863   218 net.cpp:1137] Copying source layer fc7 Type:InnerProduct #blobs=2\n",
      "I0201 22:41:36.519016   218 net.cpp:1137] Copying source layer relu7 Type:ReLU #blobs=0\n",
      "I0201 22:41:36.519049   218 net.cpp:1137] Copying source layer drop7 Type:Dropout #blobs=0\n",
      "I0201 22:41:36.519062   218 net.cpp:1137] Copying source layer fc8 Type:InnerProduct #blobs=2\n",
      "I0201 22:41:36.519094   218 net.cpp:1129] Ignoring source layer loss\n",
      "whale\n"
     ]
    }
   ],
   "source": [
    "!python submission.py '/dli/data/whale/data/train/face/w_1.jpg'  #This should return \"whale\" at the very bottom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0201 22:41:18.917516   203 gpu_memory.cpp:105] GPUMemory::Manager initialized\n",
      "I0201 22:41:18.918262   203 gpu_memory.cpp:107] Total memory: 11996954624, Free: 11790385152, dev_info[0]: total=11996954624 free=11790385152\n",
      "W0201 22:41:18.918334   203 _caffe.cpp:172] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0201 22:41:18.918470   203 _caffe.cpp:173] Use this instead (with the named \"weights\" parameter):\n",
      "W0201 22:41:18.918488   203 _caffe.cpp:175] Net('/dli/data/digits/20190201-222749-1fd6/deploy.prototxt', 1, weights='/dli/data/digits/20190201-222749-1fd6/snapshot_iter_540.caffemodel')\n",
      "I0201 22:41:18.918848   203 upgrade_proto.cpp:66] Attempting to upgrade input file specified using deprecated input fields: /dli/data/digits/20190201-222749-1fd6/deploy.prototxt\n",
      "I0201 22:41:18.918879   203 upgrade_proto.cpp:69] Successfully upgraded file specified using deprecated input fields.\n",
      "W0201 22:41:18.918890   203 upgrade_proto.cpp:71] Note that future Caffe releases will only support input layers and not input fields.\n",
      "I0201 22:41:18.929227   203 net.cpp:79] Initializing net from parameters: \n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"input\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 1\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"conv2\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0.1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"conv3\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0.1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0.1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.005\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0.1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.005\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0.1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc8\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc8\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  inner_product_param {\n",
      "    num_output: 2\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"softmax\"\n",
      "  type: \"Softmax\"\n",
      "  bottom: \"fc8\"\n",
      "  top: \"softmax\"\n",
      "}\n",
      "I0201 22:41:18.929687   203 net.cpp:109] Using FLOAT as default forward math type\n",
      "I0201 22:41:18.929700   203 net.cpp:115] Using FLOAT as default backward math type\n",
      "I0201 22:41:18.929711   203 layer_factory.hpp:172] Creating layer 'input' of type 'Input'\n",
      "I0201 22:41:18.929728   203 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0201 22:41:18.929746   203 net.cpp:199] Created Layer input (0)\n",
      "I0201 22:41:18.929759   203 net.cpp:541] input -> data\n",
      "I0201 22:41:18.930547   203 net.cpp:259] Setting up input\n",
      "I0201 22:41:18.930577   203 net.cpp:266] TEST Top shape for layer 0 'input' 1 3 227 227 (154587)\n",
      "I0201 22:41:18.930593   203 layer_factory.hpp:172] Creating layer 'conv1' of type 'Convolution'\n",
      "I0201 22:41:18.930601   203 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0201 22:41:18.930636   203 net.cpp:199] Created Layer conv1 (1)\n",
      "I0201 22:41:18.930651   203 net.cpp:571] conv1 <- data\n",
      "I0201 22:41:18.930660   203 net.cpp:541] conv1 -> conv1\n",
      "I0201 22:41:19.489346   203 net.cpp:259] Setting up conv1\n",
      "I0201 22:41:19.489403   203 net.cpp:266] TEST Top shape for layer 1 'conv1' 1 96 55 55 (290400)\n",
      "I0201 22:41:19.489439   203 layer_factory.hpp:172] Creating layer 'relu1' of type 'ReLU'\n",
      "I0201 22:41:19.489459   203 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0201 22:41:19.489481   203 net.cpp:199] Created Layer relu1 (2)\n",
      "I0201 22:41:19.489496   203 net.cpp:571] relu1 <- conv1\n",
      "I0201 22:41:19.489511   203 net.cpp:526] relu1 -> conv1 (in-place)\n",
      "I0201 22:41:19.489543   203 net.cpp:259] Setting up relu1\n",
      "I0201 22:41:19.489557   203 net.cpp:266] TEST Top shape for layer 2 'relu1' 1 96 55 55 (290400)\n",
      "I0201 22:41:19.489568   203 layer_factory.hpp:172] Creating layer 'norm1' of type 'LRN'\n",
      "I0201 22:41:19.489580   203 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0201 22:41:19.489612   203 net.cpp:199] Created Layer norm1 (3)\n",
      "I0201 22:41:19.489624   203 net.cpp:571] norm1 <- conv1\n",
      "I0201 22:41:19.489630   203 net.cpp:541] norm1 -> norm1\n",
      "I0201 22:41:19.489698   203 net.cpp:259] Setting up norm1\n",
      "I0201 22:41:19.489717   203 net.cpp:266] TEST Top shape for layer 3 'norm1' 1 96 55 55 (290400)\n",
      "I0201 22:41:19.489723   203 layer_factory.hpp:172] Creating layer 'pool1' of type 'Pooling'\n",
      "I0201 22:41:19.489735   203 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0201 22:41:19.489784   203 net.cpp:199] Created Layer pool1 (4)\n",
      "I0201 22:41:19.489796   203 net.cpp:571] pool1 <- norm1\n",
      "I0201 22:41:19.489802   203 net.cpp:541] pool1 -> pool1\n",
      "I0201 22:41:19.489869   203 net.cpp:259] Setting up pool1\n",
      "I0201 22:41:19.489886   203 net.cpp:266] TEST Top shape for layer 4 'pool1' 1 96 27 27 (69984)\n",
      "I0201 22:41:19.489899   203 layer_factory.hpp:172] Creating layer 'conv2' of type 'Convolution'\n",
      "I0201 22:41:19.489912   203 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0201 22:41:19.489936   203 net.cpp:199] Created Layer conv2 (5)\n",
      "I0201 22:41:19.489948   203 net.cpp:571] conv2 <- pool1\n",
      "I0201 22:41:19.489961   203 net.cpp:541] conv2 -> conv2\n",
      "I0201 22:41:19.497110   203 net.cpp:259] Setting up conv2\n",
      "I0201 22:41:19.497138   203 net.cpp:266] TEST Top shape for layer 5 'conv2' 1 256 27 27 (186624)\n",
      "I0201 22:41:19.497157   203 layer_factory.hpp:172] Creating layer 'relu2' of type 'ReLU'\n",
      "I0201 22:41:19.497171   203 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0201 22:41:19.497180   203 net.cpp:199] Created Layer relu2 (6)\n",
      "I0201 22:41:19.497191   203 net.cpp:571] relu2 <- conv2\n",
      "I0201 22:41:19.497215   203 net.cpp:526] relu2 -> conv2 (in-place)\n",
      "I0201 22:41:19.497238   203 net.cpp:259] Setting up relu2\n",
      "I0201 22:41:19.497253   203 net.cpp:266] TEST Top shape for layer 6 'relu2' 1 256 27 27 (186624)\n",
      "I0201 22:41:19.497265   203 layer_factory.hpp:172] Creating layer 'norm2' of type 'LRN'\n",
      "I0201 22:41:19.497277   203 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0201 22:41:19.497295   203 net.cpp:199] Created Layer norm2 (7)\n",
      "I0201 22:41:19.497306   203 net.cpp:571] norm2 <- conv2\n",
      "I0201 22:41:19.497325   203 net.cpp:541] norm2 -> norm2\n",
      "I0201 22:41:19.497385   203 net.cpp:259] Setting up norm2\n",
      "I0201 22:41:19.497406   203 net.cpp:266] TEST Top shape for layer 7 'norm2' 1 256 27 27 (186624)\n",
      "I0201 22:41:19.497424   203 layer_factory.hpp:172] Creating layer 'pool2' of type 'Pooling'\n",
      "I0201 22:41:19.497439   203 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0201 22:41:19.497450   203 net.cpp:199] Created Layer pool2 (8)\n",
      "I0201 22:41:19.497462   203 net.cpp:571] pool2 <- norm2\n",
      "I0201 22:41:19.497481   203 net.cpp:541] pool2 -> pool2\n",
      "I0201 22:41:19.497555   203 net.cpp:259] Setting up pool2\n",
      "I0201 22:41:19.497573   203 net.cpp:266] TEST Top shape for layer 8 'pool2' 1 256 13 13 (43264)\n",
      "I0201 22:41:19.497588   203 layer_factory.hpp:172] Creating layer 'conv3' of type 'Convolution'\n",
      "I0201 22:41:19.497603   203 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0201 22:41:19.497625   203 net.cpp:199] Created Layer conv3 (9)\n",
      "I0201 22:41:19.497638   203 net.cpp:571] conv3 <- pool2\n",
      "I0201 22:41:19.497651   203 net.cpp:541] conv3 -> conv3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0201 22:41:19.513682   203 net.cpp:259] Setting up conv3\n",
      "I0201 22:41:19.513712   203 net.cpp:266] TEST Top shape for layer 9 'conv3' 1 384 13 13 (64896)\n",
      "I0201 22:41:19.513734   203 layer_factory.hpp:172] Creating layer 'relu3' of type 'ReLU'\n",
      "I0201 22:41:19.513753   203 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0201 22:41:19.513767   203 net.cpp:199] Created Layer relu3 (10)\n",
      "I0201 22:41:19.513783   203 net.cpp:571] relu3 <- conv3\n",
      "I0201 22:41:19.513795   203 net.cpp:526] relu3 -> conv3 (in-place)\n",
      "I0201 22:41:19.513816   203 net.cpp:259] Setting up relu3\n",
      "I0201 22:41:19.513830   203 net.cpp:266] TEST Top shape for layer 10 'relu3' 1 384 13 13 (64896)\n",
      "I0201 22:41:19.513845   203 layer_factory.hpp:172] Creating layer 'conv4' of type 'Convolution'\n",
      "I0201 22:41:19.513855   203 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0201 22:41:19.513878   203 net.cpp:199] Created Layer conv4 (11)\n",
      "I0201 22:41:19.513895   203 net.cpp:571] conv4 <- conv3\n",
      "I0201 22:41:19.513906   203 net.cpp:541] conv4 -> conv4\n",
      "I0201 22:41:19.526386   203 net.cpp:259] Setting up conv4\n",
      "I0201 22:41:19.526415   203 net.cpp:266] TEST Top shape for layer 11 'conv4' 1 384 13 13 (64896)\n",
      "I0201 22:41:19.526466   203 layer_factory.hpp:172] Creating layer 'relu4' of type 'ReLU'\n",
      "I0201 22:41:19.526480   203 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0201 22:41:19.526494   203 net.cpp:199] Created Layer relu4 (12)\n",
      "I0201 22:41:19.526506   203 net.cpp:571] relu4 <- conv4\n",
      "I0201 22:41:19.526517   203 net.cpp:526] relu4 -> conv4 (in-place)\n",
      "I0201 22:41:19.526540   203 net.cpp:259] Setting up relu4\n",
      "I0201 22:41:19.526552   203 net.cpp:266] TEST Top shape for layer 12 'relu4' 1 384 13 13 (64896)\n",
      "I0201 22:41:19.526566   203 layer_factory.hpp:172] Creating layer 'conv5' of type 'Convolution'\n",
      "I0201 22:41:19.526576   203 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0201 22:41:19.526597   203 net.cpp:199] Created Layer conv5 (13)\n",
      "I0201 22:41:19.526612   203 net.cpp:571] conv5 <- conv4\n",
      "I0201 22:41:19.526624   203 net.cpp:541] conv5 -> conv5\n",
      "I0201 22:41:19.534807   203 net.cpp:259] Setting up conv5\n",
      "I0201 22:41:19.534835   203 net.cpp:266] TEST Top shape for layer 13 'conv5' 1 256 13 13 (43264)\n",
      "I0201 22:41:19.534858   203 layer_factory.hpp:172] Creating layer 'relu5' of type 'ReLU'\n",
      "I0201 22:41:19.534878   203 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0201 22:41:19.534893   203 net.cpp:199] Created Layer relu5 (14)\n",
      "I0201 22:41:19.534909   203 net.cpp:571] relu5 <- conv5\n",
      "I0201 22:41:19.534921   203 net.cpp:526] relu5 -> conv5 (in-place)\n",
      "I0201 22:41:19.534945   203 net.cpp:259] Setting up relu5\n",
      "I0201 22:41:19.534960   203 net.cpp:266] TEST Top shape for layer 14 'relu5' 1 256 13 13 (43264)\n",
      "I0201 22:41:19.534970   203 layer_factory.hpp:172] Creating layer 'pool5' of type 'Pooling'\n",
      "I0201 22:41:19.534981   203 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0201 22:41:19.535003   203 net.cpp:199] Created Layer pool5 (15)\n",
      "I0201 22:41:19.535017   203 net.cpp:571] pool5 <- conv5\n",
      "I0201 22:41:19.535027   203 net.cpp:541] pool5 -> pool5\n",
      "I0201 22:41:19.535101   203 net.cpp:259] Setting up pool5\n",
      "I0201 22:41:19.535120   203 net.cpp:266] TEST Top shape for layer 15 'pool5' 1 256 6 6 (9216)\n",
      "I0201 22:41:19.535126   203 layer_factory.hpp:172] Creating layer 'fc6' of type 'InnerProduct'\n",
      "I0201 22:41:19.535143   203 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0201 22:41:19.535169   203 net.cpp:199] Created Layer fc6 (16)\n",
      "I0201 22:41:19.535182   203 net.cpp:571] fc6 <- pool5\n",
      "I0201 22:41:19.535189   203 net.cpp:541] fc6 -> fc6\n",
      "I0201 22:41:20.240115   203 net.cpp:259] Setting up fc6\n",
      "I0201 22:41:20.240173   203 net.cpp:266] TEST Top shape for layer 16 'fc6' 1 4096 (4096)\n",
      "I0201 22:41:20.240198   203 layer_factory.hpp:172] Creating layer 'relu6' of type 'ReLU'\n",
      "I0201 22:41:20.240214   203 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0201 22:41:20.240231   203 net.cpp:199] Created Layer relu6 (17)\n",
      "I0201 22:41:20.240244   203 net.cpp:571] relu6 <- fc6\n",
      "I0201 22:41:20.240257   203 net.cpp:526] relu6 -> fc6 (in-place)\n",
      "I0201 22:41:20.240280   203 net.cpp:259] Setting up relu6\n",
      "I0201 22:41:20.240293   203 net.cpp:266] TEST Top shape for layer 17 'relu6' 1 4096 (4096)\n",
      "I0201 22:41:20.240299   203 layer_factory.hpp:172] Creating layer 'drop6' of type 'Dropout'\n",
      "I0201 22:41:20.240312   203 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0201 22:41:20.240326   203 net.cpp:199] Created Layer drop6 (18)\n",
      "I0201 22:41:20.240337   203 net.cpp:571] drop6 <- fc6\n",
      "I0201 22:41:20.240344   203 net.cpp:526] drop6 -> fc6 (in-place)\n",
      "I0201 22:41:20.274858   203 net.cpp:259] Setting up drop6\n",
      "I0201 22:41:20.274885   203 net.cpp:266] TEST Top shape for layer 18 'drop6' 1 4096 (4096)\n",
      "I0201 22:41:20.274894   203 layer_factory.hpp:172] Creating layer 'fc7' of type 'InnerProduct'\n",
      "I0201 22:41:20.274911   203 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0201 22:41:20.274940   203 net.cpp:199] Created Layer fc7 (19)\n",
      "I0201 22:41:20.274981   203 net.cpp:571] fc7 <- fc6\n",
      "I0201 22:41:20.274991   203 net.cpp:541] fc7 -> fc7\n",
      "I0201 22:41:20.589030   203 net.cpp:259] Setting up fc7\n",
      "I0201 22:41:20.589088   203 net.cpp:266] TEST Top shape for layer 19 'fc7' 1 4096 (4096)\n",
      "I0201 22:41:20.589118   203 layer_factory.hpp:172] Creating layer 'relu7' of type 'ReLU'\n",
      "I0201 22:41:20.589138   203 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0201 22:41:20.589161   203 net.cpp:199] Created Layer relu7 (20)\n",
      "I0201 22:41:20.589177   203 net.cpp:571] relu7 <- fc7\n",
      "I0201 22:41:20.589195   203 net.cpp:526] relu7 -> fc7 (in-place)\n",
      "I0201 22:41:20.589224   203 net.cpp:259] Setting up relu7\n",
      "I0201 22:41:20.589241   203 net.cpp:266] TEST Top shape for layer 20 'relu7' 1 4096 (4096)\n",
      "I0201 22:41:20.589254   203 layer_factory.hpp:172] Creating layer 'drop7' of type 'Dropout'\n",
      "I0201 22:41:20.589270   203 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0201 22:41:20.589293   203 net.cpp:199] Created Layer drop7 (21)\n",
      "I0201 22:41:20.589306   203 net.cpp:571] drop7 <- fc7\n",
      "I0201 22:41:20.589323   203 net.cpp:526] drop7 -> fc7 (in-place)\n",
      "I0201 22:41:20.623924   203 net.cpp:259] Setting up drop7\n",
      "I0201 22:41:20.623952   203 net.cpp:266] TEST Top shape for layer 21 'drop7' 1 4096 (4096)\n",
      "I0201 22:41:20.623965   203 layer_factory.hpp:172] Creating layer 'fc8' of type 'InnerProduct'\n",
      "I0201 22:41:20.623980   203 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0201 22:41:20.624001   203 net.cpp:199] Created Layer fc8 (22)\n",
      "I0201 22:41:20.624017   203 net.cpp:571] fc8 <- fc7\n",
      "I0201 22:41:20.624029   203 net.cpp:541] fc8 -> fc8\n",
      "I0201 22:41:20.625108   203 net.cpp:259] Setting up fc8\n",
      "I0201 22:41:20.625133   203 net.cpp:266] TEST Top shape for layer 22 'fc8' 1 2 (2)\n",
      "I0201 22:41:20.625151   203 layer_factory.hpp:172] Creating layer 'softmax' of type 'Softmax'\n",
      "I0201 22:41:20.625164   203 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0201 22:41:20.625195   203 net.cpp:199] Created Layer softmax (23)\n",
      "I0201 22:41:20.625212   203 net.cpp:571] softmax <- fc8\n",
      "I0201 22:41:20.625224   203 net.cpp:541] softmax -> softmax\n",
      "I0201 22:41:20.625324   203 net.cpp:259] Setting up softmax\n",
      "I0201 22:41:20.625342   203 net.cpp:266] TEST Top shape for layer 23 'softmax' 1 2 (2)\n",
      "I0201 22:41:20.625365   203 net.cpp:337] softmax does not need backward computation.\n",
      "I0201 22:41:20.625380   203 net.cpp:337] fc8 does not need backward computation.\n",
      "I0201 22:41:20.625392   203 net.cpp:337] drop7 does not need backward computation.\n",
      "I0201 22:41:20.625411   203 net.cpp:337] relu7 does not need backward computation.\n",
      "I0201 22:41:20.625423   203 net.cpp:337] fc7 does not need backward computation.\n",
      "I0201 22:41:20.625430   203 net.cpp:337] drop6 does not need backward computation.\n",
      "I0201 22:41:20.625440   203 net.cpp:337] relu6 does not need backward computation.\n",
      "I0201 22:41:20.625447   203 net.cpp:337] fc6 does not need backward computation.\n",
      "I0201 22:41:20.625458   203 net.cpp:337] pool5 does not need backward computation.\n",
      "I0201 22:41:20.625464   203 net.cpp:337] relu5 does not need backward computation.\n",
      "I0201 22:41:20.625474   203 net.cpp:337] conv5 does not need backward computation.\n",
      "I0201 22:41:20.625486   203 net.cpp:337] relu4 does not need backward computation.\n",
      "I0201 22:41:20.625504   203 net.cpp:337] conv4 does not need backward computation.\n",
      "I0201 22:41:20.625519   203 net.cpp:337] relu3 does not need backward computation.\n",
      "I0201 22:41:20.625530   203 net.cpp:337] conv3 does not need backward computation.\n",
      "I0201 22:41:20.625545   203 net.cpp:337] pool2 does not need backward computation.\n",
      "I0201 22:41:20.625556   203 net.cpp:337] norm2 does not need backward computation.\n",
      "I0201 22:41:20.625571   203 net.cpp:337] relu2 does not need backward computation.\n",
      "I0201 22:41:20.625587   203 net.cpp:337] conv2 does not need backward computation.\n",
      "I0201 22:41:20.625599   203 net.cpp:337] pool1 does not need backward computation.\n",
      "I0201 22:41:20.625645   203 net.cpp:337] norm1 does not need backward computation.\n",
      "I0201 22:41:20.625658   203 net.cpp:337] relu1 does not need backward computation.\n",
      "I0201 22:41:20.625669   203 net.cpp:337] conv1 does not need backward computation.\n",
      "I0201 22:41:20.625684   203 net.cpp:337] input does not need backward computation.\n",
      "I0201 22:41:20.625694   203 net.cpp:379] This network produces output softmax\n",
      "I0201 22:41:20.625735   203 net.cpp:402] Top memory (TEST) required for data: 8315264 diff: 8315264\n",
      "I0201 22:41:20.625748   203 net.cpp:405] Bottom memory (TEST) required for data: 8315256 diff: 8315256\n",
      "I0201 22:41:20.625761   203 net.cpp:408] Shared (in-place) memory (TEST) by data: 2665856 diff: 2665856\n",
      "I0201 22:41:20.625774   203 net.cpp:411] Parameters memory (TEST) required for data: 227505672 diff: 227505672\n",
      "I0201 22:41:20.625783   203 net.cpp:414] Parameters shared memory (TEST) by data: 0 diff: 0\n",
      "I0201 22:41:20.625797   203 net.cpp:420] Network initialization done.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0201 22:41:20.760576   203 net.cpp:1129] Ignoring source layer train-data\n",
      "I0201 22:41:20.760628   203 net.cpp:1137] Copying source layer conv1 Type:Convolution #blobs=2\n",
      "I0201 22:41:20.760752   203 net.cpp:1137] Copying source layer relu1 Type:ReLU #blobs=0\n",
      "I0201 22:41:20.760768   203 net.cpp:1137] Copying source layer norm1 Type:LRN #blobs=0\n",
      "I0201 22:41:20.760780   203 net.cpp:1137] Copying source layer pool1 Type:Pooling #blobs=0\n",
      "I0201 22:41:20.760790   203 net.cpp:1137] Copying source layer conv2 Type:Convolution #blobs=2\n",
      "I0201 22:41:20.761054   203 net.cpp:1137] Copying source layer relu2 Type:ReLU #blobs=0\n",
      "I0201 22:41:20.761070   203 net.cpp:1137] Copying source layer norm2 Type:LRN #blobs=0\n",
      "I0201 22:41:20.761080   203 net.cpp:1137] Copying source layer pool2 Type:Pooling #blobs=0\n",
      "I0201 22:41:20.761090   203 net.cpp:1137] Copying source layer conv3 Type:Convolution #blobs=2\n",
      "I0201 22:41:20.761693   203 net.cpp:1137] Copying source layer relu3 Type:ReLU #blobs=0\n",
      "I0201 22:41:20.761709   203 net.cpp:1137] Copying source layer conv4 Type:Convolution #blobs=2\n",
      "I0201 22:41:20.762166   203 net.cpp:1137] Copying source layer relu4 Type:ReLU #blobs=0\n",
      "I0201 22:41:20.762181   203 net.cpp:1137] Copying source layer conv5 Type:Convolution #blobs=2\n",
      "I0201 22:41:20.762495   203 net.cpp:1137] Copying source layer relu5 Type:ReLU #blobs=0\n",
      "I0201 22:41:20.762512   203 net.cpp:1137] Copying source layer pool5 Type:Pooling #blobs=0\n",
      "I0201 22:41:20.762522   203 net.cpp:1137] Copying source layer fc6 Type:InnerProduct #blobs=2\n",
      "I0201 22:41:20.785658   203 net.cpp:1137] Copying source layer relu6 Type:ReLU #blobs=0\n",
      "I0201 22:41:20.785696   203 net.cpp:1137] Copying source layer drop6 Type:Dropout #blobs=0\n",
      "I0201 22:41:20.785701   203 net.cpp:1137] Copying source layer fc7 Type:InnerProduct #blobs=2\n",
      "I0201 22:41:20.795974   203 net.cpp:1137] Copying source layer relu7 Type:ReLU #blobs=0\n",
      "I0201 22:41:20.796006   203 net.cpp:1137] Copying source layer drop7 Type:Dropout #blobs=0\n",
      "I0201 22:41:20.796015   203 net.cpp:1137] Copying source layer fc8 Type:InnerProduct #blobs=2\n",
      "I0201 22:41:20.796058   203 net.cpp:1129] Ignoring source layer loss\n",
      "not whale\n"
     ]
    }
   ],
   "source": [
    "!python submission.py '/dli/data/whale/data/train/not_face/w_1.jpg'  #This should return \"not whale\" at the very bottom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "Assessment1.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
